# ğŸ“ æ•°æ®åŠ è½½ï¼šè¯»å–å›¾åƒå’Œç›¸æœºå‚æ•°
# ğŸ¯ å°„çº¿ç”Ÿæˆï¼šä¸ºæ¯ä¸ªåƒç´ ç”Ÿæˆ3Då°„çº¿
# ğŸ“Š ç‚¹é‡‡æ ·ï¼šæ²¿å°„çº¿é‡‡æ ·3Dç‚¹ç”¨äºä½“ç§¯æ¸²æŸ“
# ğŸ”„ æ‰¹é‡å¤„ç†ï¼šç»„ç»‡æ•°æ®ä¾›ç¥ç»ç½‘ç»œè®­ç»ƒ

import os
import json 
import torch
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import numpy as np

# åŠ è½½åˆæˆæ•°æ®é›†çš„ç±»ï¼Œç»§æ‰¿è‡ªPyTorchçš„Dataset
class LoadSyntheticDataset(Dataset):
    def __init__(self, path_to_images, path_to_labels):

        # æ£€æŸ¥å›¾ç‰‡ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(path_to_images):
            raise FileNotFoundError(f"Images directory not found: {path_to_images}")

        # æ£€æŸ¥æ ‡ç­¾æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(path_to_labels):
            raise FileNotFoundError(f"Labels file not found: {path_to_labels}")
            
        self.path_to_images = path_to_images
        # è·å–ç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶ï¼Œç­›é€‰å‡ºPNGå›¾ç‰‡
        all_files = os.listdir(path_to_images)
        self.images = [im for im in all_files if im.endswith('.png')]

        # å›¾åƒè½¬æ¢ï¼šPILå›¾åƒ â†’ PyTorchå¼ é‡
        self.transform = transforms.ToTensor()
        
        try:
            # å°è¯•æ‰“å¼€å¹¶è¯»å–JSONæ–‡ä»¶
            with open(path_to_labels, 'r') as f:
                # å°†JSONå†…å®¹è§£æä¸ºPythonå­—å…¸ï¼ŒåŒ…å«ç›¸æœºå‚æ•°
                self.labels = json.load(f)
            # è·å–camera_angle_xçš„å€¼ï¼ˆç›¸æœºè§†è§’è§’åº¦ï¼Œç”¨äºè®¡ç®—ç„¦è·ï¼‰ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
            self.camera_angle_x = self.labels.get('camera_angle_x', None)
        except Exception as e:  # å¦‚æœä¸Šé¢ä»»ä½•ä¸€æ­¥å‡ºé”™
            # é‡æ–°æŠ›å‡ºé”™è¯¯ï¼Œè®©è°ƒç”¨è€…å¤„ç†
            raise

    # ä¸ºå›¾åƒä¸­çš„æ¯ä¸ªåƒç´ ç”Ÿæˆä¸€æ¡3Då°„çº¿ï¼Œç”¨äºåç»­çš„ä½“ç§¯æ¸²æŸ“
    def get_origins_and_directions(self, frame, width, height):  # widthã€heightåˆ†åˆ«ä¸ºå›¾åƒçš„å®½é«˜
        # frameæ˜¯æ˜¯å­—å…¸ï¼ŒåŒ…å«å•å¼ å›¾åƒçš„ç›¸æœºå‚æ•°ï¼Œä¹Ÿå°±æ˜¯æä¾›ç›¸æœºå¤–å‚é€šå¸¸åŒ…æ‹¬ï¼š
        # frame = {
        #     'file_path': 'path/to/image.png',
        #     'transform_matrix': [
        #         [R11, R12, R13, T1],  # æ—‹è½¬çŸ©é˜µçš„ç¬¬1è¡Œ + å¹³ç§»å‘é‡çš„ç¬¬1ä¸ªåˆ†é‡
        #         [R21, R22, R23, T2],  # æ—‹è½¬çŸ©é˜µçš„ç¬¬2è¡Œ + å¹³ç§»å‘é‡çš„ç¬¬2ä¸ªåˆ†é‡
        #         [R31, R32, R33, T3],  # æ—‹è½¬çŸ©é˜µçš„ç¬¬3è¡Œ + å¹³ç§»å‘é‡çš„ç¬¬3ä¸ªåˆ†é‡
        #         [0, 0, 0, 1]  # é½æ¬¡åæ ‡çš„æœ€åä¸€è¡Œ
        #     ]
        # }

        # å–å‡ºâ€œä¸–ç•Œâ†’ç›¸æœºâ€å¤–å‚çŸ©é˜µï¼ˆ4Ã—4ï¼‰ï¼Œå¹¶è½¬æˆ torch å¼ é‡
        origins = torch.tensor(frame['transform_matrix'], dtype=torch.float32)
        # å–çŸ©é˜µç¬¬ 4 åˆ—å‰ 3 ä¸ªå…ƒç´  â†’ ç›¸æœºå…‰å¿ƒåœ¨ä¸–ç•Œåæ ‡ç³»ä¸­çš„ä½ç½®
        origins = origins[:3, 3]  # [3]

        # æŠŠä¸€ç»´å‘é‡æ”¹æˆ 2-Dï¼Œæ–¹ä¾¿åé¢æ‰¹é‡å¤åˆ¶
        origins = origins.view(1, 3)  # [1, 3]
        # å¤åˆ¶HÃ—Wä»½ï¼Œä½¿æ¯æ¡åƒç´ å°„çº¿éƒ½æœ‰ä¸€ä»½èµ·ç‚¹ï¼Œå‚æ•°ï¼š0ç»´å¤åˆ¶width * heightä»½ï¼Œ1ç»´å¤åˆ¶1ä»½
        origins = origins.repeat(width * height, 1)  # [H*W, 3]

        # å»ºç«‹åƒç´ åæ ‡ç½‘æ ¼
        # i å¯¹åº”åˆ—ç´¢å¼•ï¼ˆxï¼‰ï¼Œj å¯¹åº”è¡Œç´¢å¼•ï¼ˆyï¼‰ï¼›indexing='xy' ä¿è¯é¡ºåºæ­£ç¡®
        i, j = torch.meshgrid(
            torch.arange(width, dtype=torch.float32),
            torch.arange(height, dtype=torch.float32),
            indexing='xy'  # i/j å½¢çŠ¶éƒ½æ˜¯ [H, W]
            )   

        # å‡è®¾ä¼ æ„Ÿå™¨å®½åº¦ = å›¾åƒå®½åº¦çš„ä¸€åŠ â†’ ç®—å‡ºç„¦è·
        focal = width / 2
        # æŠŠåƒç´ åæ ‡è½¬æˆç›¸æœºç©ºé—´ä¸‹çš„å½’ä¸€åŒ–åæ ‡ï¼ˆæˆåƒå¹³é¢z = -1ï¼‰
        x = (i - width * 0.5) / focal 
        y = (j - height * 0.5) / focal
        # ç›¸æœºæœ -Z æ–¹å‘çœ‹
        z = -torch.ones_like(x) * 1

        # æ‹¼æˆ3Dæ–¹å‘å‘é‡å¹¶å‹æ‰æˆäºŒç»´æ•°ç»„
        directions = torch.stack((x, y, z), dim=-1)  # [H, W, 3]
        directions = directions.view(-1, 3)  # [H*W, 3]

        return origins, directions

    # ä»å·²ç»ç”Ÿæˆçš„å…¨éƒ¨å°„çº¿é‡Œï¼ŒéšæœºæŠ½ N_rays æ¡
    def sample_random_rays(self, rays_o, rays_d, N_rays):
        total_rays = rays_o.shape[0] # æ€»å°„çº¿é‡ rays_0===>[H*w, 3],total_rays = h*W
        # éšæœºé€‰æ‹©N_raysæ¡å°„çº¿çš„ç´¢å¼•
        indices = torch.randint(0, total_rays, (N_rays,))   # [N_rays]

        # æ ¹æ®ç´¢å¼•é‡‡æ ·åŸç‚¹å’Œæ–¹å‘
        rays_o_sampled = rays_o[indices]  # [N_rays, 3]
        rays_d_sampled = rays_d[indices]  # [N_rays, 3]

        return rays_o_sampled, rays_d_sampled

    # æ²¿å°„çº¿é‡‡æ ·ç‚¹ï¼ˆç”¨äºä½“ç§¯æ¸²æŸ“ï¼‰
    def get_rays_sampling(self, origins, directions, near, far, samples):
        # ç”Ÿæˆ samples ä¸ªæ·±åº¦å€¼ï¼ŒèŒƒå›´ [near, far]
        z_vals = torch.linspace(near, far, steps=samples)  # [samples]
        # åŠ ä¸¤ç»´å ä½ï¼Œæ–¹ä¾¿åé¢å¹¿æ’­
        # [samples] â†’ [1, samples, 1]
        z_vals = z_vals[None, :, None]  # [1, samples, 1]

        # æŠŠèµ·ç‚¹ã€æ–¹å‘ä¹Ÿå‡ç»´ï¼Œå˜æˆ [N_rays, 1, 3]
        origins = origins[:, None, :]     # [N_rays, 1, 3]
        directions = directions[:, None, :]  # [N_rays, 1, 3]

        #  å¹¿æ’­ä¹˜æ³•ï¼šæ¯æ¡å°„çº¿æ²¿è‡ªèº«æ–¹å‘èµ° z_vals æ·±åº¦ï¼Œå¾—åˆ°é‡‡æ ·ç‚¹
        # origins + directions * z_vals
        # å¹¿æ’­åï¼š [N_rays, 1, 3] * [1, samples, 1] â†’ [N_rays, samples, 3]
        points = origins + directions * z_vals  # [N_rays, samples, 3]

        # è¿”å›é‡‡æ ·ç‚¹åæ ‡ & å¯¹åº”çš„æ·±åº¦å€¼ï¼ˆå»æ‰å¤šä½™ç»´åº¦ï¼‰
        # points: [N_rays, samples, 3]
        # z_vals: [samples]
        # squeeze() æŠŠé•¿åº¦ä¸º1çš„ç»´åº¦å»æ‰
        return points.float(), z_vals.squeeze(0)  # z_vals: [samples] â†’ used for rendering

    # è¿”å›æ•°æ®é›†å¤§å°ï¼ˆå›¾åƒæ•°é‡ï¼‰
    def __len__(self): 
        return len(self.images)

    # æ ¸å¿ƒæ–¹æ³•ï¼šè·å–å•ä¸ªæ•°æ®é¡¹
    def __getitem__ (self, idx): 
        try:
            # è·å–å½“å‰å›¾åƒçš„æ ‡ç­¾ä¿¡æ¯ï¼ˆä»JSONæ–‡ä»¶ä¸­è¯»å–çš„ç›¸æœºå‚æ•°ï¼‰
            label = self.labels['frames'][idx]
            # æ„å»ºå›¾åƒæ–‡ä»¶è·¯å¾„ï¼ˆä»æ ‡ç­¾ä¸­è·å–æ–‡ä»¶åå¹¶æ·»åŠ .pngåç¼€ï¼‰
            file_name = os.path.basename(label['file_path']) + '.png'
            img_path = os.path.join(self.path_to_images, file_name)

            # æ£€æŸ¥å›¾åƒæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(img_path):
                raise FileNotFoundError(f"Image file not found: {img_path}")

            # æ‰“å¼€å›¾åƒæ–‡ä»¶å¹¶è½¬æ¢ä¸ºRGBæ ¼å¼ï¼ˆç¡®ä¿3é€šé“ï¼‰
            image = Image.open(img_path).convert("RGB")  # (H, W, 3)

            # å¦‚æœå®šä¹‰äº†å›¾åƒè½¬æ¢å‡½æ•°ï¼ˆå°†PILå›¾åƒè½¬æ¢ä¸ºPyTorchå¼ é‡ï¼‰
                # # åœ¨ __init__ æ–¹æ³•ä¸­ï¼š
                # self.transform = transforms.ToTensor()  # è¿™æ˜¯ä¸€ä¸ªå‡½æ•°å¯¹è±¡
                # # åœ¨ __getitem__ æ–¹æ³•ä¸­ï¼š
                # if self.transform:  # å› ä¸º self.transform æ˜¯ä¸€ä¸ªå‡½æ•°å¯¹è±¡ï¼Œæ‰€ä»¥ä¸º True
                #     image = self.transform(image)  # æ‰§è¡Œå›¾åƒè½¬æ¢
            if self.transform:
                # transforms.ToTensor()å®Œæˆä¸¤ä¸ªæ“ä½œï¼š
                # 1ã€å°†PIL Imageè½¬æ¢ä¸ºPyTorchå¼ é‡
                # 2ã€å°†ç»´åº¦é¡ºåºä»HWCæ”¹ä¸ºCHW
                image = self.transform(image)  # (3, H, W,)

            # è®¾ç½®å…‰çº¿æ•°é‡
            N_rays = 4096
            # è·å–å›¾åƒçš„é«˜åº¦å’Œå®½åº¦
            H, W = image.shape[1], image.shape[2]

            # å¦‚æœæœ‰ç›¸æœºè§†è§’å‚æ•°ï¼Œä½¿ç”¨å…¬å¼è®¡ç®—ç„¦è·
            if self.camera_angle_x is not None:
                focal = W / (2 * np.tan(self.camera_angle_x / 2))
            else:
                # å¦‚æœæ²¡æœ‰ç›¸æœºå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤ç„¦è·ï¼ˆå®½åº¦çš„ä¸€åŠï¼‰
                focal = W / 2

            # éšæœºé€‰åƒç´ åæ ‡ï¼ˆåœ¨å›¾åƒä¸Šéšæœºé€‰æ‹©4096ä¸ªç‚¹ä½œä¸ºå°„çº¿ï¼‰
            i = torch.randint(0, W, (N_rays,))  # éšæœºXåæ ‡
            j = torch.randint(0, H, (N_rays,))  # éšæœºYåæ ‡

            # è·å–è¿™äº›åƒç´ ç‚¹çš„çœŸå®RGBé¢œè‰²å€¼
            # image[:, j, i]ï¼šè·å–æ‰€æœ‰é€šé“åœ¨(j,i)ä½ç½®çš„å€¼ â†’ [3, N_rays]
            # .permute(1, 0)ï¼šè½¬ç½®ç»´åº¦ â†’ [N_rays, 3]
            rgb_gt = image[:, j, i].permute(1, 0)  # [N_rays, 3]

            # ========åƒç´ â†’æˆåƒå¹³é¢â†’ç›¸æœºç©ºé—´æ–¹å‘=======
            x = (i.float() - W * 0.5) / focal  # Xåæ ‡æ ‡å‡†åŒ–
            y = (j.float() - H * 0.5) / focal  # Yåæ ‡æ ‡å‡†åŒ–
            z = -torch.ones_like(x)  # Zåæ ‡è®¾ä¸º-1ï¼ˆæŒ‡å‘ç›¸æœºå‰æ–¹ï¼‰
            # ç»„åˆæˆæ–¹å‘å‘é‡ [N_rays, 3]
            dirs = torch.stack([x, y, z], dim=-1)  # [N_rays, 3]

            # ========ç›¸æœºç©ºé—´æ–¹å‘â†’ä¸–ç•Œåæ ‡=======
            # å–ç›¸æœºåˆ°ä¸–ç•Œåæ ‡çš„å˜æ¢çŸ©é˜µ
            c2w = torch.tensor(label['transform_matrix'], dtype=torch.float32)  # [4, 4]
            # å°†å°„çº¿æ–¹å‘ä»ç›¸æœºåæ ‡ç³»è½¬æ¢åˆ°ä¸–ç•Œåæ ‡ç³»
            # @ è¡¨ç¤ºçŸ©é˜µä¹˜æ³•ï¼Œc2w[:3, :3].T æ˜¯æ—‹è½¬çŸ©é˜µçš„è½¬ç½®
            # c2w:å­˜å‚¨çš„æ˜¯ä¸–ç•Œåˆ°ç›¸æœºçš„æ—‹è½¬çŸ©é˜µï¼Œæ‰€ä»¥ç›¸æœºåˆ°ä¸–ç•Œè¦åšè½¬ç½®
            rays_d = (dirs @ c2w[:3, :3].T).float()  # Rotate ray directions
            # å–å‡ºç›¸æœºå…‰å¿ƒåæ ‡ï¼ˆåæ ‡ï¼Œä¸æ˜¯æ–¹å‘å‘é‡ï¼Œæ‰€ä»¥ä¸ç”¨ä¹˜ä»¥æ—‹è½¬çŸ©é˜µï¼‰
            rays_o = c2w[:3, 3].expand(rays_d.shape)  # [N_rays, 3]

            # è®¾ç½®é‡‡æ ·èŒƒå›´
            near, far = 2.0, 6.0
            # å‡åŒ€é‡‡æ ·64ä¸ªç‚¹
            t_vals = torch.linspace(0., 1., steps=64)
            # çº¿æ€§æ’å€¼
            # æŠŠåœ¨ [0, 1] åŒºé—´çš„ t_vals æ˜ å°„åˆ°å®é™…çš„ [near, far] æ·±åº¦èŒƒå›´ï¼Œå¾—åˆ°æ¯æ¡å°„çº¿ä»è¿‘åˆ°è¿œçš„é‡‡æ ·æ·±åº¦ z_vals
            z_vals = near * (1. - t_vals) + far * t_vals  # [64]
            # expand()åªæ‰©å¼ ç»´åº¦é•¿åº¦ä¸º1çš„ç»´åº¦
            z_vals = z_vals.expand(N_rays, -1)  # [N_rays, 64]

            # åˆ†å±‚é‡‡æ ·ï¼ˆhierarchical samplingï¼‰ - è®©é‡‡æ ·ç‚¹æ›´é›†ä¸­åœ¨é‡è¦åŒºåŸŸ
            mids = 0.5 * (z_vals[..., 1:] + z_vals[..., :-1]) # è®¡ç®—ä¸­é—´ç‚¹
            # ä¸Šè¾¹ç•Œå’Œä¸‹è¾¹ç•Œï¼Œä»–ä»¬å¯¹åº”ä½ç½®ç»„åˆå°±æ˜¯ä¸€ä¸ªè¾¹ç•ŒåŒºé—´ï¼Œä»–ä»¬æ˜¯ç›¸äº’é”™å¼€çš„é‚£ç§
            upper = torch.cat([mids, z_vals[..., -1:]], -1)
            lower = torch.cat([z_vals[..., :1], mids], -1)
            t_rand = torch.rand_like(z_vals)  # éšæœºåç§»é‡
            z_vals = lower + (upper - lower) * t_rand  # åœ¨æ¯ä¸ªåŒºé—´å†…éšæœºé‡‡æ ·ï¼ˆæé«˜é‡‡æ ·æ•ˆç‡ï¼‰

            # è®¡ç®—3Dç©ºé—´ä¸­çš„é‡‡æ ·ç‚¹åæ ‡
            # å°„çº¿å…¬å¼ï¼špoints = ray_origin + ray_direction * depth
            # rays_o[:, None, :]ï¼šä» [N_rays, 3] æ‰©å±•ä¸º [N_rays, 1, 3]
            # rays_d[:, None, :]ï¼šä» [N_rays, 3] æ‰©å±•ä¸º [N_rays, 1, 3]
            # z_vals[..., :, None]ï¼šä» [N_rays, 64] æ‰©å±•ä¸º [N_rays, 64, 1]
            points = rays_o[:, None, :] + rays_d[:, None, :] * z_vals[..., :, None]  # [N_rays, 64, 3]

            # è¿”å›æ•°æ®å­—å…¸ï¼ˆç”¨äºè®­ç»ƒï¼‰
            return {
                'points': points,  # 3Dé‡‡æ ·ç‚¹åæ ‡ [N_rays, 64, 3]
                'rays_d': rays_d,  # å°„çº¿æ–¹å‘ [N_rays, 3]
                'rgb_gt': rgb_gt,  # çœŸå®é¢œè‰²å€¼ [N_rays, 3]
                'z_vals': z_vals   # é‡‡æ ·æ·±åº¦å€¼ [N_rays, 64]
            }
        except Exception as e:
            # å¦‚æœå¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œæ‰“å°è¯¦ç»†é”™è¯¯ä¿¡æ¯
            print(f"Error processing item {idx}: {str(e)}")
            import traceback
            traceback.print_exc()  # æ‰“å°å®Œæ•´çš„é”™è¯¯å †æ ˆè·Ÿè¸ª
            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼ˆè®©è°ƒç”¨è€…çŸ¥é“å‡ºé”™ï¼‰

# è‡ªå®šä¹‰æ•°æ®åŠ è½½å™¨ç±»
class CustomDataloader:
    # åˆå§‹åŒ–æ–¹æ³•ï¼Œåˆ›å»ºæ•°æ®åŠ è½½å™¨å®ä¾‹
    def __init__(self, batch_size, path_to_images=None, path_to_labels=None):
        # æ£€æŸ¥å‚æ•°æ˜¯å¦æä¾›ï¼Œç¡®ä¿è·¯å¾„å‚æ•°ä¸ä¸ºç©º
        if path_to_images is None or path_to_labels is None:
            # å¦‚æœä»»ä½•ä¸€ä¸ªè·¯å¾„å‚æ•°æœªæä¾›ï¼ŒæŠ›å‡ºå€¼é”™è¯¯å¼‚å¸¸
            raise ValueError("Both path_to_images and path_to_labels must be provided")

        # åˆ›å»ºæ•°æ®é›†å®ä¾‹ï¼ŒåŠ è½½åˆæˆæ•°æ®é›†
        # LoadSyntheticDatasetæ˜¯è‡ªå®šä¹‰çš„æ•°æ®é›†ç±»ï¼Œè´Ÿè´£è¯»å–å›¾åƒå’Œç›¸æœºå‚æ•°
        self.dataset = LoadSyntheticDataset(
                path_to_images=path_to_images,  # å›¾åƒæ–‡ä»¶æ‰€åœ¨ç›®å½•è·¯å¾„
                path_to_labels=path_to_labels   # ç›¸æœºå‚æ•°JSONæ–‡ä»¶è·¯å¾„
            )
        # è®¾ç½®æ‰¹é‡å¤§å°ï¼Œå³æ¯æ¬¡è®­ç»ƒæ—¶å¤„ç†çš„å›¾ç‰‡æ•°
        self.batch_size = batch_size
        # åˆ›å»ºPyTorchçš„DataLoaderå®ä¾‹ï¼Œç”¨äºæ‰¹é‡åŠ è½½æ•°æ®
        self.loader = DataLoader(self.dataset, batch_size=self.batch_size, shuffle=True)

    # å®šä¹‰è¿­ä»£å™¨æ–¹æ³•ï¼Œä½¿CustomDataloaderå¯è¿­ä»£
    # å¦‚for batch in dataloaderï¼ŒPythonä¼šè‡ªåŠ¨è°ƒç”¨ __iter__()
    def __iter__(self):
        # è¿”å›åº•å±‚DataLoaderçš„è¿­ä»£å™¨ï¼Œç”¨äºéå†æ‰€æœ‰æ•°æ®æ‰¹æ¬¡
        return iter(self.loader)

    # å®šä¹‰é•¿åº¦æ–¹æ³•ï¼Œè¿”å›æ•°æ®åŠ è½½å™¨ä¸­çš„æ‰¹æ¬¡æ•°é‡
    def __len__(self):
        # è¿”å›åº•å±‚DataLoaderçš„é•¿åº¦ï¼ˆæ€»æ‰¹æ¬¡æ•° = æ€»æ ·æœ¬æ•° / æ‰¹é‡å¤§å°ï¼‰
        return len(self.loader)

# dataset = LoadSyntheticDataset(
#     path_to_images= '/teamspace/studios/this_studio/nerf_synthetic/chair', 
#     path_to_labels= '/teamspace/studios/this_studio/nerf_synthetic/chair/transforms_train.json'
# )


# loader = DataLoader(dataset, batch_size = 4, shuffle= True)



# for points in loader: 
#     print(points.shape)
#     break
    # print(labels)
